#!/usr/bin/env python3
"""
æ–‡æ¡£ç»Ÿè®¡è„šæœ¬

åˆ†ææ–‡æ¡£è´¨é‡å’Œè¦†ç›–ç‡
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Any
import markdown
from collections import defaultdict

def count_words(text: str) -> int:
    """ç»Ÿè®¡æ–‡å­—æ•°é‡"""
    # ç§»é™¤Markdownè¯­æ³•
    text = re.sub(r'[#*`_\[\]()]', '', text)
    # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)
    # ç»Ÿè®¡ä¸­è‹±æ–‡å­—ç¬¦
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
    return chinese_chars + english_words

def extract_code_blocks(content: str) -> List[str]:
    """æå–ä»£ç å—"""
    pattern = r'```[\w]*\n(.*?)\n```'
    return re.findall(pattern, content, re.DOTALL)

def extract_links(content: str) -> Dict[str, List[str]]:
    """æå–é“¾æ¥"""
    internal_links = re.findall(r'\[([^\]]+)\]\((?!http)([^)]+)\)', content)
    external_links = re.findall(r'\[([^\]]+)\]\((https?://[^)]+)\)', content)
    
    return {
        'internal': [link[1] for link in internal_links],
        'external': [link[1] for link in external_links]
    }

def extract_images(content: str) -> List[str]:
    """æå–å›¾ç‰‡"""
    return re.findall(r'!\[([^\]]*)\]\(([^)]+)\)', content)

def analyze_markdown_file(file_path: Path) -> Dict[str, Any]:
    """åˆ†æå•ä¸ªMarkdownæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åŸºæœ¬ç»Ÿè®¡
    stats = {
        'file': str(file_path),
        'size_bytes': file_path.stat().st_size,
        'lines': len(content.splitlines()),
        'words': count_words(content),
        'characters': len(content)
    }
    
    # å†…å®¹åˆ†æ
    stats['headings'] = len(re.findall(r'^#+\s', content, re.MULTILINE))
    stats['code_blocks'] = len(extract_code_blocks(content))
    stats['links'] = extract_links(content)
    stats['images'] = len(extract_images(content))
    stats['tables'] = len(re.findall(r'^\|.*\|$', content, re.MULTILINE))
    stats['admonitions'] = len(re.findall(r'!!!\s+\w+', content))
    
    # è´¨é‡æŒ‡æ ‡
    stats['has_title'] = bool(re.search(r'^#\s+', content, re.MULTILINE))
    stats['has_description'] = 'description:' in content or len(content) > 100
    stats['has_examples'] = stats['code_blocks'] > 0
    stats['has_navigation'] = len(stats['links']['internal']) > 0
    
    return stats

def calculate_quality_score(stats: Dict[str, Any]) -> float:
    """è®¡ç®—æ–‡æ¡£è´¨é‡è¯„åˆ†"""
    score = 0
    max_score = 100
    
    # åŸºç¡€å†…å®¹ (40åˆ†)
    if stats['has_title']:
        score += 10
    if stats['has_description']:
        score += 10
    if stats['words'] >= 100:
        score += 10
    if stats['headings'] >= 2:
        score += 10
    
    # ä»£ç ç¤ºä¾‹ (20åˆ†)
    if stats['has_examples']:
        score += 15
    if stats['code_blocks'] >= 3:
        score += 5
    
    # å¯¼èˆªå’Œé“¾æ¥ (20åˆ†)
    if stats['has_navigation']:
        score += 10
    if len(stats['links']['internal']) >= 3:
        score += 5
    if len(stats['links']['external']) >= 1:
        score += 5
    
    # ä¸°å¯Œå†…å®¹ (20åˆ†)
    if stats['images'] > 0:
        score += 5
    if stats['tables'] > 0:
        score += 5
    if stats['admonitions'] > 0:
        score += 5
    if stats['words'] >= 500:
        score += 5
    
    return min(score, max_score)

def analyze_documentation() -> Dict[str, Any]:
    """åˆ†ææ•´ä¸ªæ–‡æ¡£"""
    docs_dir = Path(__file__).parent.parent / "docs"
    
    if not docs_dir.exists():
        return {"error": "æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨"}
    
    # æ”¶é›†æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(docs_dir.rglob("*.md"))
    
    if not md_files:
        return {"error": "æœªæ‰¾åˆ°Markdownæ–‡ä»¶"}
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    file_stats = []
    total_stats = defaultdict(int)
    
    for md_file in md_files:
        try:
            stats = analyze_markdown_file(md_file)
            stats['quality_score'] = calculate_quality_score(stats)
            file_stats.append(stats)
            
            # ç´¯è®¡ç»Ÿè®¡
            for key in ['words', 'lines', 'code_blocks', 'images', 'tables', 'headings']:
                total_stats[key] += stats.get(key, 0)
            
            total_stats['internal_links'] += len(stats['links']['internal'])
            total_stats['external_links'] += len(stats['links']['external'])
            
        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶ {md_file} æ—¶å‡ºé”™: {e}")
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    total_files = len(file_stats)
    avg_quality = sum(f['quality_score'] for f in file_stats) / total_files if total_files > 0 else 0
    
    # æ–‡æ¡£è¦†ç›–ç‡åˆ†æ
    coverage_stats = analyze_coverage(docs_dir)
    
    # ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡
    final_stats = {
        'generated_at': '2024-01-15T10:30:00Z',
        'total_pages': total_files,
        'total_words': total_stats['words'],
        'total_lines': total_stats['lines'],
        'code_examples': total_stats['code_blocks'],
        'images': total_stats['images'],
        'tables': total_stats['tables'],
        'headings': total_stats['headings'],
        'internal_links': total_stats['internal_links'],
        'external_links': total_stats['external_links'],
        'average_quality_score': round(avg_quality, 1),
        'quality_score': round(avg_quality, 0),
        'coverage': coverage_stats['coverage_percentage'],
        'file_details': file_stats,
        'coverage_details': coverage_stats
    }
    
    return final_stats

def analyze_coverage(docs_dir: Path) -> Dict[str, Any]:
    """åˆ†ææ–‡æ¡£è¦†ç›–ç‡"""
    # é¢„æœŸçš„æ–‡æ¡£ç»“æ„
    expected_docs = [
        'index.md',
        'getting-started/index.md',
        'getting-started/installation.md',
        'getting-started/configuration.md',
        'user-guide/index.md',
        'api-reference/index.md',
        'api-reference/mcp-tools.md',
        'best-practices/index.md',
        'examples/index.md',
        'changelog.md'
    ]
    
    existing_docs = []
    missing_docs = []
    
    for doc in expected_docs:
        doc_path = docs_dir / doc
        if doc_path.exists():
            existing_docs.append(doc)
        else:
            missing_docs.append(doc)
    
    coverage_percentage = round((len(existing_docs) / len(expected_docs)) * 100, 1)
    
    return {
        'expected_count': len(expected_docs),
        'existing_count': len(existing_docs),
        'missing_count': len(missing_docs),
        'coverage_percentage': coverage_percentage,
        'existing_docs': existing_docs,
        'missing_docs': missing_docs
    }

def generate_quality_report(stats: Dict[str, Any]) -> str:
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    report = f"""# ğŸ“Š æ–‡æ¡£è´¨é‡æŠ¥å‘Š

## æ€»ä½“ç»Ÿè®¡

- **æ€»é¡µé¢æ•°**: {stats['total_pages']}
- **æ€»å­—æ•°**: {stats['total_words']:,}
- **ä»£ç ç¤ºä¾‹**: {stats['code_examples']}
- **å›¾ç‰‡æ•°é‡**: {stats['images']}
- **å†…éƒ¨é“¾æ¥**: {stats['internal_links']}
- **å¤–éƒ¨é“¾æ¥**: {stats['external_links']}

## è´¨é‡è¯„åˆ†

**æ€»ä½“è¯„åˆ†**: {stats['quality_score']}/100

## è¦†ç›–ç‡åˆ†æ

**æ–‡æ¡£è¦†ç›–ç‡**: {stats['coverage']}%

### å·²å®Œæˆæ–‡æ¡£
"""
    
    for doc in stats['coverage_details']['existing_docs']:
        report += f"- âœ… {doc}\n"
    
    if stats['coverage_details']['missing_docs']:
        report += "\n### ç¼ºå¤±æ–‡æ¡£\n"
        for doc in stats['coverage_details']['missing_docs']:
            report += f"- âŒ {doc}\n"
    
    report += f"""
## è¯¦ç»†ç»Ÿè®¡

| æ–‡ä»¶ | å­—æ•° | è´¨é‡è¯„åˆ† | ä»£ç ç¤ºä¾‹ | é“¾æ¥æ•° |
|------|------|----------|----------|--------|
"""
    
    for file_stat in stats['file_details'][:10]:  # æ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
        file_name = Path(file_stat['file']).name
        report += f"| {file_name} | {file_stat['words']} | {file_stat['quality_score']}/100 | {file_stat['code_blocks']} | {len(file_stat['links']['internal'])} |\n"
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š åˆ†ææ–‡æ¡£ç»Ÿè®¡...")
    
    # åˆ†ææ–‡æ¡£
    stats = analyze_documentation()
    
    if 'error' in stats:
        print(f"âŒ é”™è¯¯: {stats['error']}")
        return
    
    # è¾“å‡ºJSONæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
    print(json.dumps(stats, ensure_ascii=False, indent=2))
    
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    report = generate_quality_report(stats)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(__file__).parent.parent / "docs_quality_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“‹ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {report_file}", file=sys.stderr)
    print(f"ğŸ“ˆ æ€»ä½“è´¨é‡è¯„åˆ†: {stats['quality_score']}/100", file=sys.stderr)
    print(f"ğŸ“Š æ–‡æ¡£è¦†ç›–ç‡: {stats['coverage']}%", file=sys.stderr)

if __name__ == "__main__":
    import sys
    main()
